

[1]
발표 시작하겠습니다. 
안녕하십니까? "웹브라우저렌더링을 활용한 컨테이너기반 다크웹스캐너설계"를 발표하게된 세종대학교 학부생 양찬모입니다.

[2]
발표 순서는, "연구 배경", "컨테이너기반 스캐너", "실험및결론"순으로 진행하겠습니다.

[3]
연구 배경입니다, 다크 웹 내에서 운영중인 불법서비스에 대해, 먼저 살펴보겠습니다. 

[4]
화면에서보시는바와같이 다크 웹 내에서는, 합법적으로 거래될 수 없는 마약, 총기, 

[5]
위조여권과신분증, 화폐등이 거래되고 있습니다. 

[6]
또 한, 청부살인을의뢰하거나 지난해에 이슈가 되었던 N번방과같은 성착취국내커뮤니티들도 운영되고있습니다.

[7]
이외에도 국가및기업,중요기관의 침해사고정보가 판매 혹은 유출되고 있는 상황입니다. 

[8]
그러면, 왜이런 불법서비스들이 다크 웹내에서 운영이 가능한지에 대해서 설명드리겠습니다.

[9]
 가장 큰 이유는 익명성이 보장된 네트워크입니다. 
 다크 웹은 Tor브라우저와 같이 특수한브라우저로만, 접근할수있는 암호화된 네트워크에존재합니다.
 토르 네트워크에서는 목적지까지 도달하기 위해, 데이터를 암호화하면서, 
 최소3개 이상의 익명노드들을거쳐 송수신이 이루어집니다. 
 
 송수신을 담당하는 각노드들은 자기자신을기준으로, 이전노드와 이후노드의 정보만 알고있습니다. 또한, 
 익명 노드들의 순서를 지정하는 방식도 무작위이기 때문에 최초 송신자를 식별할 수 없습니다.
 
[10]
이러한 익명 네트워크를 거쳐 외부 목적지로 나가지 않고, 
익명 네트워크 내에 위치하며, ".onion"이라는 최상위도메인을 갖는 웹 사이트들을 다크웹이라고 합니다.

[11]
다크웹 내의 불법 서비스의 차단과 예방을 위해서는 다양한 다크웹내불법서비스들의 정보를 수집하여,
연구와 수사를 용이하게 해야합니다. 

[12]
하지만, 다크웹 내 불법 서비스의 정보를 수집하기에는 몇가지 한계점이 있습니다.
첫번 째로 반드시 특수한프록시를 이용해야기 때문에 접근성이 떨어진다는 것입니다.
두번 째로는, 최소 3개 이상의 익명노드들을 거쳐 송수신이 이루어지기 때문에, 속도가 느립니다.  

[13]
이러한 문제점들을 기존 연구에서는 어떻게 해결하고자 했는지와 한계점에 대해서 살펴보겠습니다.

[14]
다크 웹에 접근하기 위해서는 "토르"라는 어플리케이션을 사용합니다. 
GUI 환경에서는 Tor Browser를 통해 다크 웹에 접근할 수있고, 
CUI 환경에서는 Tor 실행파일을 Daemon으로 실행시켜, Tor Porxy를 통해 다크웹에 접근할수 있습니다. 

[15]
2020년에 정보과학논문지에 기재된 "스크립팅작업제거를 통한토르기반다크웹수집성능개선연구"에서는 
많은 시간이 소요되는 단점을 개선하기 위해 "토르브라우저"에서 "자동으로 렌더링 되지 않도록", 
"명령행인터페이스"와 "TorProxy"를 이용하여 "평문형태의 Text정보"만을 수집합니다. 

[16]
토르브라우저를 통한 자동 렌더링 기능을 제거할 경우,
실제 불법 서비스에서 사용자에게 제공하는 이미지,
비디오파일등과 같은 시각화 정보를 수집할수 없다는 한계점이 있습니다. 

[17]
지금까지 살펴본 한계점을 정리하자면, 
특정 프록시를사용해야하는 "접근성 측면의 한계점", "속도적 측면의 한계점", "제한된 정보 수집의 한계점"이 있습니다. 

[18]
이런 문제점들을 저희 팀에서는 어떤 방식으로 해결하고자 했는지에 대해 설명드리겠습니다. 

[19] 
먼저 스캐너 구성입니다. 

[20]
관련 연구에서도 언급되었드시, 토르브라우저를 이용하여 정보를 수집할 경우, 
"렌더링에 사용될 파일들"을 "자동으로 로드하기때문에" 요청수가 늘어나게 되어 속도가 느려집니다. (click)
그렇기 때문에 저희가제안하는 스캐너도 "토르 브라우저의 렌더링을" 사용하지 않고,  
"명령행 인터페이스를" 통해 "병렬적으로정보를 수집합니다."(click)
병렬적으로 수집하는 정보는, 일반브라우저에서 해당페이지가 렌더링될 때 필요한 파일들을 대상으로 수행합니다.(click)
이렇게 수집된 정보를 기반으로 일반 웹 브라우저에서 렌더링이 가능하도록 구성했습니다. 

[21]
이를 가능하게 하기 위해서는, 
HTML내에서 브라우저렌더링에 사용될파일들을 먼저식별해야하는 기능이필요합니다. 
가장 먼저, 스캐너는 대상 페이지의 HTML 코드 내에서 파일들을 가리키는 경로들을 수집합니다.

[22]
파일을 가리키는 경로 수집이 완료되면 해당 경로에 있는 파일을 다운로드 받아 일반 브라우저에서
렌더링 될 수 있도록 HTML 코드내 경로와 저장한 파일들의 경로를 매핑해야합니다. 
토르 브라우저와 CLI 기반의 데몬 프로세스의 경우에는 단일 Tor Proxy를 통해 모든 요청을 처리하지만,
본 스캐너의 경우 도커를 사용하여 Tor Proxy를 다중으로 컨테이너화 하여 요청을 병렬 처리합니다. 

[23]
이렇게 다운로드와 매핑이 완료되면, 
다크 웹 접속이 필요 없는 일반 브라우저를 통해서 
대상 불법 사이트에 대한 웹 렌더링을 수행할 수 있습니다. 


[24]
정리하자면, 해당 스캐너의 핵심 기능은, 일반 브라우저에서 HTML 렌더링시 필요한태그와주소를 수집하는수집기와 다크웹 내요청을 병렬처리할 토르 Proxy Container입니다.
위 기능에 대해서 구체적으로 설명드리겠습니다. 

[25]
HTML 렌더링 호출 태그 및 주소 수집기입니다. 

[26]
일반적으로 브라우저에서 렌더링을 통해, 화면을 구성할때 크게 "렌더링엔진"과 "자바스크립엔진"이 사용됩니다. 
렌더링 엔진은 HTML 파서와 CSS파서를 통해 DOM 트리와 CSSOM 트리를 구축하여 렌더링 과정을 수행합니다. 
그렇기 때문에 트리 구축에 필요한 "대상 페이지의 HTML 코드"와 참조되는 "CSS파일"은 반드시 수집되어야합니다.

또한 트리가 구축되는 과정에서 자바스크립트 코드가 있으면 트리 구축을 임시 중단하고, 자바스크립트 엔젠에 의해 스크립트가 실행됩니다.
스크립트를 통해서 트리 구조가 변경될 수 있기 때문에 자바스크립트 또한 수집되어야합니다. 

그리고 마지막으로 시각화 자료나 첨부파일등 외부 참조 데이터 파일들을 수집해야합니다. 

[27]
HTML 코드 내에, 참조되는 CSS, Javscript, 외부 데이터들의 경로를 수집하기 위해 
두개의 표와 같이 태그와 속성을 선별했습니다. 

[28]
선별된 태그의속성이 가리키는주소는 크게 호스트본인의 상대주소와절대주소,
외부호스트의주소, 
다크웹이 아닌 일반네트워크에 존재하는 주소들로 구성됩니다. (click)
다크 웹 내에서 호스팅되는 주소의 경우는 명령행 인터프리터를 사용하여 다운받을 수 있도록 
호스트를 포함한 절대 주소로 변경하여 일괄 저장합니다. (click)
다크 웹이 아닌 일반 네트워크에 존재하는 주소의 경우, 일반 브라우저를 통해서도 접근할 수
있기 때문에 별도로 수집하지 않습니다. 

[29]
이렇게수집된 외부참조데이터들을 어떤방식으로 병렬로 처리할 수있도록 하는지 설명드리겠습니다. 

[30]
외부참조데이터들이 많을수록, 다크웹내에서 발생하는 패킷의수도 증가하게됩니다.
제안한 스캐너의경우, 일반다크웹스캐너에비해 많은요청이발생함에 따라 속도도느려집니다.
이를해결하기 위해병렬적으로 패킷을 전송해야합니다.
다크웹내의 병렬적으로 패킷을처리하기 위해서는, 
Tor Proxy를 "하나만구성하여" 모든패킷을 하나의프록시에 할당하는것은 한계가있습니다. 
그렇기때문에, 도커를사용하여 다중Tor Proxy컨테이너를 구동하고, 패킷들을 분할하여 
처리할 수 있도록했습니다. 

[31] 
TorProxy컨테이너를 생성할이미지를 빌드하기위해 먼저, 도커파일을 작성합니다.
기본적으로 "알파인" 이미지에 토르를 설치하고 구동하는도커파일입니다. 
이때 같은경로에 "프록시포트"를 지정하는 "설정파일"도 함께작성합니다. 

[32] 
생성한도커파일과 토르설정파일을 빌드하여 이미지를 생성합니다. (click)
이후 docker run 명령을통해 TorProxy컨테이너를 데몬모드로 실행시킵니다. (click)
생성할Tor Proxy 컨테이너 수 만큼 해당 명령을 반복하여 수행합니다. (click)
정상적으로 TorProxy컨테이너가 구동되고 있는지 확인합니다. 

[33] 
Tor Proxy 컨테이너를 통해 TorProxy가 구동되는지 확인합니다. 
도커의 경우 172.17.0.2부터 순차적으로 내부아이피가 할당됩니다. 
해당아이피와 포트로프록시를 연결하고, 퍼블릭아이피를 확인하여 프록시가 잘동작하는지 확인합니다.


[34] 
제안한 스캐너가 실제로 문제를 해결했는지에 대해설명드리겠습니다. 

[35]
먼저 실험 환경입니다. 
macOS와 intel i9 CPU와 16 기가바이트 메모리 자원을 사용하였습니다.
프록시의 경우는 Host OS에 토르프록시컨테이너 3개를 구동시켰습니다.
HTTP 요청을 병렬로 전송할 스레드는 Python 언어와 Current 패키지, request 모듈을 사용했습니다. 

[36]
일단 첫번째 실험은 다크웹내불법서비스 1개를 대상으로, 
"토르(Tor)브라우저에서의 특정페이지 렌더링완료시간"과
"Python 언어기반의 병렬스레드및, 3개의토르 프록시컨테이너를 이용하여, 
일반브러우저에서 렌더링 가능하도록 파일들을 다운로드하는 시간"을 비교 실험하였습니다. 

[37]
실험대상페이지에서는 99회의요청이 발생합니다, 이를 10회 테스트한 결과 (click)
Tor 브라우저의경우 평균 약34초가소요되었으며, 스캐너의경우 약15초가소요되었습니다. 
이를통해 토르브라우저에서의 렌더링완료 시간보다 약2배의 성능개선을 확인했습니다.

[38]
두번째실험으로는 "토르브라우저가 대상페이지를 접속하여 렌더링한 결과"와 
"스캐너를 통해다운로드한 파일및HTML을 일반브라우저"에서 렌더링한결과가 일치하는지에 대해 실험했습니다. 

[39]
좌측탭이 토르브라우저를 통해대상 페이지를 방문한화면이고, 
우측탭이 크롬브라우저를 통해저장한HTML을 방문한 화면입니다. 
화면상 동일하게 렌더링이 되었음을 확인할 수있습니다.

[40]
"조금더 세부적으로, 
개발자 도구를 사용하여 정상적으로 외부참조데이터들을 동일하게 로드하는지도 확인할수 있었습니다."

[41]
"또한 크롬브라우저에서 해당페이지내의 CSS와자바스크립트가 잘동작하는지 확인하였고,
수집된 파일들은 파일 탐색기를 통해 확인할 수 있기 때문에 정상적으로 정보수집이완료되었다고 판단할수있습니다. 

[42] 
결론 및 향후연구입니다. 

[43] 
탐색한 문제를 해결하기 위해 본연구에서는 토르(Tor) Proxy 컨테이너를 다수 생성하고, 
해당Proxy컨테이너에 HTTP요청을 분할및병렬 전송하여, 
빠른속도로 렌더링에 필요한파일을 다운로드하는 컨테이너기반스캐너를 제안했습니다.

이를통해 당시다크웹불법서비스에서 제공하는 시각정보를 다크웹접속없이 일반웹브라우저를 통해 확인및수집할수 있습니다.
본 연구에서는 다크 웹 불법 서비스가 수행하는 기능적인 측면, 즉 백엔드 기능까지 확인할 수 없다는 한계점이 있습니다. 
향후 연구에서는 해당 스캐너를 통해 다크 웹 정보를 하나의 공용 데이터 베이스에 중앙화하여, 
불법 서비스의 기능을 유추할 수 있는 연구를 수행할 계획입니다.

[44]
참고 문헌 및 사사입니다. 

[45] 
"웹브라우저 렌더링을활용한 컨테이너기반 다크웹스캐너 설계"발표, 모두 마치겠습니다. 
들어주셔서 감사합니다. 

